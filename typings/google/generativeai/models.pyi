"""
This type stub file was generated by pyright.
"""

import typing
import google.ai.generativelanguage as glm
from typing import Any
from google.generativeai import operations, protos
from google.generativeai.types import helper_types, model_types

"""
This type stub file was generated by pyright.
"""
def get_model(name: model_types.AnyModelNameOptions, *, client=..., request_options: helper_types.RequestOptionsType | None = ...) -> model_types.Model | model_types.TunedModel:
    """Calls the API to fetch a model by name.

    ```
    import pprint
    model = genai.get_model('models/gemini-pro')
    pprint.pprint(model)
    ```

    Args:
        name: The name of the model to fetch. Should start with `models/`
        client: The client to use.
        request_options: Options for the request.

    Returns:
        A `types.Model`
    """
    ...

def get_base_model(name: model_types.BaseModelNameOptions, *, client=..., request_options: helper_types.RequestOptionsType | None = ...) -> model_types.Model:
    """Calls the API to fetch a base model by name.

    ```
    import pprint
    model = genai.get_base_model('models/chat-bison-001')
    pprint.pprint(model)
    ```

    Args:
        name: The name of the model to fetch. Should start with `models/`
        client: The client to use.
        request_options: Options for the request.

    Returns:
        A `types.Model`.
    """
    ...

def get_tuned_model(name: model_types.TunedModelNameOptions, *, client=..., request_options: helper_types.RequestOptionsType | None = ...) -> model_types.TunedModel:
    """Calls the API to fetch a tuned model by name.

    ```
    import pprint
    model = genai.get_tuned_model('tunedModels/gemini-1.0-pro-001')
    pprint.pprint(model)
    ```

    Args:
        name: The name of the model to fetch. Should start with `tunedModels/`
        client: The client to use.
        request_options: Options for the request.

    Returns:
        A `types.TunedModel`.
    """
    ...

def get_base_model_name(model: model_types.AnyModelNameOptions, client: glm.ModelServiceClient | None = ...):
    """Calls the API to fetch the base model name of a model."""
    ...

def list_models(*, page_size: int | None = ..., client: glm.ModelServiceClient | None = ..., request_options: helper_types.RequestOptionsType | None = ...) -> model_types.ModelsIterable:
    """Calls the API to list all available models.

    ```
    import pprint
    for model in genai.list_models():
        pprint.pprint(model)
    ```

    Args:
        page_size: How many `types.Models` to fetch per page (api call).
        client: You may pass a `glm.ModelServiceClient` instead of using the default client.
        request_options: Options for the request.

    Yields:
        `types.Model` objects.

    """
    ...

def list_tuned_models(*, page_size: int | None = ..., client: glm.ModelServiceClient | None = ..., request_options: helper_types.RequestOptionsType | None = ...) -> model_types.TunedModelsIterable:
    """Calls the API to list all tuned models.

    ```
    import pprint
    for model in genai.list_tuned_models():
        pprint.pprint(model)
    ```

    Args:
        page_size: How many `types.Models` to fetch per page (api call).
        client: You may pass a `glm.ModelServiceClient` instead of using the default client.
        request_options: Options for the request.

    Yields:
        `types.TunedModel` objects.
    """
    ...

def create_tuned_model(source_model: model_types.AnyModelNameOptions, training_data: model_types.TuningDataOptions, *, id: str | None = ..., display_name: str | None = ..., description: str | None = ..., temperature: float | None = ..., top_p: float | None = ..., top_k: int | None = ..., epoch_count: int | None = ..., batch_size: int | None = ..., learning_rate: float | None = ..., input_key: str = ..., output_key: str = ..., client: glm.ModelServiceClient | None = ..., request_options: helper_types.RequestOptionsType | None = ...) -> operations.CreateTunedModelOperation:
    """Calls the API to initiate a tuning process that optimizes a model for specific data, returning an operation object to track and manage the tuning progress.

    Since tuning a model can take significant time, this API doesn't wait for the tuning to complete.
    Instead, it returns a `google.api_core.operation.Operation` object that lets you check on the
    status of the tuning job, or wait for it to complete, and check the result.

    After the job completes you can either find the resulting `TunedModel` object in
    `Operation.result()` or `palm.list_tuned_models` or `palm.get_tuned_model(model_id)`.

    ```
    my_id = "my-tuned-model-id"
    operation = palm.create_tuned_model(
      id = my_id,
      source_model="models/text-bison-001",
      training_data=[{'text_input': 'example input', 'output': 'example output'},...]
    )
    tuned_model=operation.result()      # Wait for tuning to finish

    palm.generate_text(f"tunedModels/{my_id}", prompt="...")
    ```

    Args:
        source_model: The name of the model to tune.
        training_data: The dataset to tune the model on. This must be either:
          * A `protos.Dataset`, or
          * An `Iterable` of:
            *`protos.TuningExample`,
            * `{'text_input': text_input, 'output': output}` dicts
            * `(text_input, output)` tuples.
          * A `Mapping` of `Iterable[str]` - use `input_key` and `output_key` to choose which
            columns to use as the input/output
          * A csv file (will be read with `pd.read_csv` and handles as a `Mapping`
            above). This can be:
            * A local path as a `str` or `pathlib.Path`.
            * A url for a csv file.
            * The url of a Google Sheets file.
          * A JSON file - Its contents will be handled either as an `Iterable` or `Mapping`
            above. This can be:
            * A local path as a `str` or `pathlib.Path`.
        id: The model identifier, used to refer to the model in the API
          `tunedModels/{id}`. Must be unique.
        display_name: A human-readable name for display.
        description: A description of the tuned model.
        temperature: The default temperature for the tuned model, see `types.Model` for details.
        top_p: The default `top_p` for the model, see `types.Model` for details.
        top_k: The default `top_k` for the model, see `types.Model` for details.
        epoch_count: The number of tuning epochs to run. An epoch is a pass over the whole dataset.
        batch_size: The number of examples to use in each training batch.
        learning_rate: The step size multiplier for the gradient updates.
        client: Which client to use.
        request_options: Options for the request.

    Returns:
        A [`google.api_core.operation.Operation`](https://googleapis.dev/python/google-api-core/latest/operation.html)
    """
    ...

@typing.overload
def update_tuned_model(tuned_model: protos.TunedModel, updates: None = ..., *, client: glm.ModelServiceClient | None = ..., request_options: helper_types.RequestOptionsType | None = ...) -> model_types.TunedModel:
    ...

@typing.overload
def update_tuned_model(tuned_model: str, updates: dict[str, Any], *, client: glm.ModelServiceClient | None = ..., request_options: helper_types.RequestOptionsType | None = ...) -> model_types.TunedModel:
    ...

def update_tuned_model(tuned_model: str | protos.TunedModel, updates: dict[str, Any] | None = ..., *, client: glm.ModelServiceClient | None = ..., request_options: helper_types.RequestOptionsType | None = ...) -> model_types.TunedModel:
    """Calls the API to push updates to a specified tuned model where only certain attributes are updatable."""
    ...

def delete_tuned_model(tuned_model: model_types.TunedModelNameOptions, client: glm.ModelServiceClient | None = ..., request_options: helper_types.RequestOptionsType | None = ...) -> None:
    """Calls the API to delete a specified tuned model"""
    ...

